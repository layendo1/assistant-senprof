
/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */

// Polyfill for browser environment
if (typeof process === 'undefined') {
  window.process = { env: {} };
}

import { GoogleGenAI, Type } from '@google/genai';
import { marked } from 'marked';

// Configure marked to open all links in a new tab for user convenience and security.
const renderer = new marked.Renderer();
// FIX: The signature for the marked.js link renderer has been updated.
// It now accepts a single token object. The `title` property is optional,
// and the link content is in the `tokens` property, which needs to be parsed.
// We use a standard function to get the correct `this` context for the parser.
renderer.link = function({ href, title, tokens }) {
  const text = this.parser.parseInline(tokens);
  return `<a href="${href}" title="${title || ''}" target="_blank" rel="noopener noreferrer">${text}</a>`;
};
marked.use({ renderer });


// DOM Elements
const body = document.body;
const chatContainer = document.querySelector('.chat-container');
const header = document.querySelector('header');
const chatHistory = document.getElementById('chat-history');
const chatForm = document.getElementById('chat-form');
const chatInput = document.getElementById('chat-input');
const langSelect = document.getElementById('lang-select');
const submitButton = chatForm.querySelector('button[type="submit"]');
const micButton = document.getElementById('mic-button');
const imageUploadButton = document.getElementById('image-upload-button');
const imageUploadInput = document.getElementById('image-upload-input');
const imagePreviewContainer = document.getElementById('image-preview-container');
const imagePreview = document.getElementById('image-preview');
const removeImageButton = document.getElementById('remove-image-button');
const loadingIndicator = document.getElementById('loading-indicator');
const loadingText = document.getElementById('loading-text');
const helpButton = document.getElementById('help-button');
const settingsButton = document.getElementById('settings-button');
const settingsPanel = document.getElementById('settings-panel');
const closeSettingsButton = document.getElementById('close-settings-button');
const soundToggle = document.getElementById('sound-toggle');
const soundThemeGroup = document.getElementById('sound-theme-group');
const clearHistoryButton = document.getElementById('clear-history-button');
const uiLangSelect = document.getElementById('ui-lang-select');
const themeToggle = document.getElementById('theme-toggle');
const textSizeToggle = document.getElementById('text-size-toggle');
const playbackSpeedToggle = document.getElementById('playback-speed-toggle');
const suggestionChipsContainer = document.getElementById('suggestion-chips-container');
const favoritesList = document.getElementById('favorites-list');
const shareButton = document.getElementById('share-button');
const shareModalOverlay = document.getElementById('share-modal-overlay');
const closeShareModalButton = document.getElementById('close-share-modal-button');
const copyTranscriptionButton = document.getElementById('copy-transcription-button');
const exportPdfButton = document.getElementById('export-pdf-button');
const userRoleSelect = document.getElementById('user-role-select');
const userLevelSelect = document.getElementById('user-level-select');
const avatarContainer = document.getElementById('avatar-container');
const embedButton = document.getElementById('embed-button');
const embedCodeContainer = document.getElementById('embed-code-container');
const embedCodeTextarea = document.getElementById('embed-code-textarea');
const copyEmbedCodeButton = document.getElementById('copy-embed-code-button');

// Voice Settings DOM Elements
const voiceSelect = document.getElementById('voice-select');
const pitchSlider = document.getElementById('pitch-slider');
const voicePreviewButton = document.getElementById('voice-preview-button');


// Web Audio API
let audioContext = null;

// Chat History
const MAX_HISTORY_MESSAGES = 50;
let chatHistoryLog = [];

// App State
let favorites = [];
let currentAudioSource = null;
let currentlyPlayingButton = null;
let loadingInterval = null;
let isFetchingSuggestions = false;
let isGoogleTtsAvailable = false;
const fallbackSuggestions = ["ğŸ“š Explorer les cours de science", "ğŸ“ Commencer un tutoriel de programmation", "ğŸ“ Chercher des guides d'Ã©tude"];
let attachedImage = null;


// App Settings
let settings = {
  soundEnabled: true,
  soundTheme: 'default',
  uiLang: 'fr',
  theme: 'dark',
  textSize: 'normal',
  playbackSpeed: 1,
  userRole: 'enseignant',
  userLevel: 'all',
  voiceName: '',
  pitch: 1,
};

// --- Internationalization (i18n) ---
const translations = {
  fr: {
    appTitle: "Khadija",
    appSubtitle: "Votre assistant pour la plateforme Senprof",
    settingsTitle: "ParamÃ¨tres",
    uiLanguage: "Langue de l'interface",
    enableSounds: "Activer les sons",
    soundTheme: "ThÃ¨me sonore",
    defaultTheme: "DÃ©faut",
    softTheme: "Doux",
    digitalTheme: "NumÃ©rique",
    history: "Historique",
    clearHistory: "Vider l'historique",
    openSettings: "Ouvrir les paramÃ¨tres",
    closeSettings: "Fermer les paramÃ¨tres",
    help: "Aide",
    openChat: "Ouvrir l'assistante",
    recordMessage: "Enregistrer un message vocal",
    stopRecording: "ArrÃªter l'enregistrement",
    sendMessage: "Envoyer le message",
    chatPlaceholder: "Posez une question en franÃ§ais, wolof, arabe...",
    recordingPlaceholder: "Enregistrement en cours...",
    assistantThinking: "Khadija rÃ©flÃ©chit...",
    analyzingRequest: "Analyse de votre demande...",
    consultingResources: "Consultation des ressources...",
    formulatingResponse: "Formulation de la rÃ©ponse...",
    welcomeMessage: "Bonjour ! Je suis l'assistante Khadija. Posez votre question sur la plateforme Senprof.",
    helpTitle: "Besoin d'aide ?",
    helpP1: "Je suis Khadija. Mon rÃ´le est de vous aider Ã  trouver des ressources sur la plateforme Senprof.",
    helpP2: "Vous pouvez me poser des questions en :",
    helpLangs: "FranÃ§ais, Wolof, Arabe",
    helpVoice: "<strong>Pour la saisie vocale :</strong> Assurez-vous de sÃ©lectionner la bonne langue dans le menu dÃ©roulant Ã  cÃ´tÃ© du bouton micro avant de commencer l'enregistrement.",
    genericError: "DÃ©solÃ©, une erreur est survenue. Veuillez rÃ©essayer.",
    networkError: "Il semble y avoir un problÃ¨me de connexion. Veuillez vÃ©rifier votre accÃ¨s Ã  internet et rÃ©essayer.",
    apiKeyError: "Il y a un problÃ¨me avec la configuration de l'application. Veuillez contacter le support.",
    rateLimitError: "L'assistante reÃ§oit trop de demandes en ce moment. Veuillez patienter un instant avant de rÃ©essayer.",
    modelError: "Le modÃ¨le d'IA n'a pas pu traiter cette demande. Veuillez essayer de reformuler votre question ou rÃ©essayer plus tard.",
    blockedContentError: "La rÃ©ponse a Ã©tÃ© bloquÃ©e car elle pourrait enfreindre les rÃ¨gles de sÃ©curitÃ©. Veuillez modifier votre question.",
    imageLoadError: "Impossible de charger l'image sÃ©lectionnÃ©e. Veuillez essayer un autre fichier.",
    micPermissionError: "L'accÃ¨s au microphone a Ã©tÃ© refusÃ©. Veuillez l'autoriser dans les paramÃ¨tres de votre navigateur.",
    speechError: "Erreur de reconnaissance vocale. Veuillez rÃ©essayer.",
    sources: "Source(s) :",
    theme: "ThÃ¨me",
    lightTheme: "Clair",
    darkTheme: "Sombre",
    textSize: "Taille du texte",
    smallSize: "P",
    normalSize: "M",
    largeSize: "G",
    playbackSpeed: "Vitesse de lecture",
    favorites: "Mes Favoris",
    noFavorites: "Aucun favori pour le moment. Cliquez sur l'icÃ´ne ğŸ”– sur un message pour l'enregistrer.",
    removeFavorite: "Supprimer le favori",
    shareConversation: "Partager la conversation",
    copyTranscription: "Copier la transcription",
    exportPdf: "TÃ©lÃ©charger en PDF",
    transcriptionCopied: "Transcription copiÃ©e !",
    userProfile: "Mon Profil",
    userRole: "Je suis un(e)...",
    userLevel: "Niveau/Classe",
    roleTeacher: "Enseignant",
    roleStudent: "Ã‰lÃ¨ve",
    roleParent: "Parent",
    summarize: "RÃ©sumer",
    createQuiz: "CrÃ©er un Quiz",
    summarizing: "RÃ©sumÃ© en cours...",
    quizCreating: "CrÃ©ation du quiz...",
    quizCorrect: "Correct !",
    quizIncorrect: "Incorrect.",
    addFavoriteTooltip: "Ajouter aux favoris",
    removeFavoriteTooltip: "Retirer des favoris",
    summarizeTooltip: "RÃ©sumer ce contenu",
    createQuizTooltip: "CrÃ©er un quiz sur ce contenu",
    previewSoundTooltip: "AperÃ§u du thÃ¨me sonore",
    clearHistoryTooltip: "Supprimer dÃ©finitivement tous les messages",
    copyTranscriptionTooltip: "Copier la conversation en format texte",
    exportPdfTooltip: "TÃ©lÃ©charger la conversation en format PDF",
    closeShareModalTooltip: "Fermer la fenÃªtre",
    userSender: "Utilisateur",
    assistantSender: "Khadija",
    playAudioTooltip: "Lire le message",
    pauseAudioTooltip: "ArrÃªter la lecture",
    appearanceSettings: "Apparence",
    soundSettings: "Audio & Sons",
    dataManagement: "Gestion des DonnÃ©es",
    uploadImageTooltip: "Joindre une image",
    assistantVoice: "Voix de l'assistante",
    voice: "Voix",
    pitch: "Hauteur",
    previewVoice: "Ã‰couter un aperÃ§u",
    previewVoiceText: "Bonjour, je suis Khadija. C'est un plaisir de vous aider.",
    noVoiceAvailable: "Aucune voix disponible",
    embed: "IntÃ©grer",
    embedTooltip: "Obtenir le code d'intÃ©gration (Iframe)",
    copyCode: "Copier le code",
    codeCopied: "Code copiÃ© !",
  },
  wo: {
    appTitle: "Khadija",
    appSubtitle: "Sa ndimal ngir jot ci ay ressources ci Senprof",
    settingsTitle: "ParamÃ¨tres",
    uiLanguage: "LÃ kku Interface",
    enableSounds: "Activer son yi",
    soundTheme: "Teeamu son",
    defaultTheme: "Default",
    softTheme: "Doux",
    digitalTheme: "NumÃ©rique",
    history: "Historique",
    clearHistory: "Effacer historique",
    openSettings: "Ubbi paramÃ¨tres yi",
    closeSettings: "TÃ«j paramÃ¨tres yi",
    help: "Ndimal",
    openChat: "Ubbi ndimal bi",
    recordMessage: "Enregistrer baat",
    stopRecording: "Taxawal enregistrement",
    sendMessage: "YÃ³nne baat",
    chatPlaceholder: "Laajal sa laaj ci franÃ§ais, wolof, arabe...",
    recordingPlaceholder: "Enregistrement...",
    assistantThinking: "Khadija mi ngi xalaat...",
    analyzingRequest: "Mingi saytu laaj bi...",
    consultingResources: "Mingi doxantu ci kÃ ggu yi...",
    formulatingResponse: "Mingi taxawal tontu bi...",
    welcomeMessage: "Salaam aleekum ! Man la Khadija, sa ndimalu Senprof. Laajal sa laaj.",
    helpTitle: "Soo soxla ndimbal?",
    helpP1: "Man Khadija laa. Sama liggÃ©ey mooy dimbali leen ngeen giss ay ressources ci Senprof.",
    helpP2: "MÃ«n nga maa laaj ay laaj ci:",
    helpLangs: "FranÃ§ais, Wolof, Arabe",
    helpVoice: "<strong>Ngir enregistrer baat:</strong> Verifieral bu baax ne tÃ nn nga lÃ kk bi gÃ«n ci menu bi ci wetu micro bi laata ngay tambali.",
    genericError: "JÃ©ggalu, am na njuumte. Ngir nga jÃ©emaat.",
    networkError: "Problem am na ci connexion bi. Seetal sa internet te jÃ©emaat.",
    apiKeyError: "Problem am na ci configuration application bi. Jookool ak support bi.",
    rateLimitError: "Assistant bi dafa am laaj yu bari. Xaaral tuuti te jÃ©emaat.",
    modelError: "ModÃ¨le IA bi mÃ«nu la traiter laaj bi. JÃ©emaatal wala nga laajee beneen anam.",
    blockedContentError: "Tontu bi daÃ±u ko bloquÃ© ndax mÃ«n na jalgati rÃ¨gle yi. Soppil sa laaj.",
    imageLoadError: "MÃ«nuÃ±u charger nataal bi. JÃ©emaatal beneen.",
    micPermissionError: "DaÃ±o baÃ± accÃ¨s ci micro bi. Ngir nga nangul ko ci paramÃ¨tres navigateur bi.",
    speechError: "Njuumte ci xammu baat. JÃ©emaatal.",
    sources: "Source(s):",
    theme: "ThÃ¨me",
    lightTheme: "Leer",
    darkTheme: "LÃ«ndÃ«m",
    textSize: "RÃ©yaayu Mbind",
    smallSize: "N",
    normalSize: "Y",
    largeSize: "M",
    playbackSpeed: "Gawantu wu wax",
    favorites: "Samay Favoris",
    noFavorites: "Amuloo ab favori. Klikal ci ğŸ”– ci bÃ©pp message ngir denc ko.",
    removeFavorite: "Dindi favori bi",
    shareConversation: "Partager waxtaan wi",
    copyTranscription: "Copier mbind mi",
    exportPdf: "Yebal ci PDF",
    transcriptionCopied: "Mbind mi copiÃ© naÃ±u ko!",
    userProfile: "Sama Profiil",
    userRole: "Man...",
    userLevel: "Niveau/Classe",
    roleTeacher: "JÃ ngalekat",
    roleStudent: "Ndongo",
    roleParent: "Way-jur",
    summarize: "Tekki",
    createQuiz: "Defar ab Quiz",
    summarizing: "Dafa nekk ci tekki...",
    quizCreating: "Dafa nekk ci defar quiz...",
    quizCorrect: "Deug na!",
    quizIncorrect: "Deugul.",
    addFavoriteTooltip: "Yok ci favori",
    removeFavoriteTooltip: "Dindi ci favori",
    summarizeTooltip: "Tekkil li ci biir",
    createQuizTooltip: "Defaral quiz ci li",
    previewSoundTooltip: "NdÃ©glul teeamu son bi",
    clearHistoryTooltip: "Dindi bÃ©pp message bu fi nekk",
    copyTranscriptionTooltip: "Copier waxtaan wi ci text",
    exportPdfTooltip: "Yebal waxtaan wi ci PDF",
    closeShareModalTooltip: "TÃ«jal palanteer bi",
    userSender: "JÃ«fandikukat",
    assistantSender: "Khadija",
    playAudioTooltip: "JÃ ngal message bi",
    pauseAudioTooltip: "Taxawal",
    appearanceSettings: "Noo mu Mele",
    soundSettings: "Son yi",
    dataManagement: "Saytu DonnÃ©es yi",
    uploadImageTooltip: "YÃ³nne nataal",
    assistantVoice: "Baatu ndimal bi",
    voice: "Baat",
    pitch: "Tollu",
    previewVoice: "Deglu misaal",
    previewVoiceText: "Salaam aleekum, man Khadija laa. BÃ©g naa lool ci dimbali leen.",
    noVoiceAvailable: "Amul benn baat",
    embed: "Duggal",
    embedTooltip: "JÃ«l code ngir duggal ko ci site",
    copyCode: "Copier code bi",
    codeCopied: "Copie na!",
  },
  ar: {
    appTitle: "Khadija",
    appSubtitle: "Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ù„Ù…Ù†ØµØ© Senprof",
    settingsTitle: "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª",
    uiLanguage: "Ù„ØºØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©",
    enableSounds: "ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø£ØµÙˆØ§Øª",
    soundTheme: "Ø³Ù…Ø© Ø§Ù„ØµÙˆØª",
    defaultTheme: "Ø§ÙØªØ±Ø§Ø¶ÙŠ",
    softTheme: "Ù†Ø§Ø¹Ù…",
    digitalTheme: "Ø±Ù‚Ù…ÙŠ",
    history: "Ø§Ù„Ø³Ø¬Ù„",
    clearHistory: "Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„",
    openSettings: "ÙØªØ­ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª",
    closeSettings: "Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª",
    help: "Ù…Ø³Ø§Ø¹Ø¯Ø©",
    openChat: "ÙØªØ­ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯",
    recordMessage: "ØªØ³Ø¬ÙŠÙ„ Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©",
    stopRecording: "Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„",
    sendMessage: "Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©",
    chatPlaceholder: "Ø§Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„ÙˆÙ„ÙˆÙÙŠØ©",
    recordingPlaceholder: "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„...",
    assistantThinking: "Khadija ØªÙÙƒØ±...",
    analyzingRequest: "Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø·Ù„Ø¨Ùƒ...",
    consultingResources: "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯...",
    formulatingResponse: "Ø¬Ø§Ø±ÙŠ ØµÙŠØ§ØºØ© Ø§Ù„Ø±Ø¯...",
    welcomeMessage: "Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! Ø£Ù†Ø§ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Khadija. Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ùƒ Ø­ÙˆÙ„ Ù…Ù†ØµØ© Senprof.",
    helpTitle: "Ù‡Ù„ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø¹Ø¯Ø©ØŸ",
    helpP1: "Ø£Ù†Ø§ Khadija. Ø¯ÙˆØ±ÙŠ Ù‡Ùˆ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¹Ù„Ù‰ Ù…Ù†ØµØ© Senprof.",
    helpP2: "ÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªØ³Ø£Ù„Ù†ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø¨Ù€:",
    helpLangs: "Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©ØŒ Ø§Ù„ÙˆÙ„ÙˆÙØŒ Ø§Ù„Ø¨ÙˆÙ„Ø§Ø±ØŒ Ø§Ù„Ø³ÙŠØ±ÙŠØ±ØŒ Ø§Ù„Ø¯ÙŠÙˆÙ„Ø§ØŒ Ø§Ù„Ù…Ø§Ù†Ø¯ÙŠÙ†ÙƒØ§",
    helpVoice: "<strong>Ù„Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ:</strong> ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© Ø¨Ø¬ÙˆØ§Ø± Ø²Ø± Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù‚Ø¨Ù„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„.",
    genericError: "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ù…Ø§. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
    networkError: "ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„Ùƒ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙˆØ§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
    apiKeyError: "Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØªÙƒÙˆÙŠÙ† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¯Ø¹Ù….",
    rateLimitError: "ÙŠØªÙ„Ù‚Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø¯Ø¯Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ Ù…Ù† Ø§Ù„Ø·Ù„Ø¨Ø§Øª ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ø­Ø¸Ø© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
    modelError: "Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‡Ø°Ø§ Ø§Ù„Ø·Ù„Ø¨. ÙŠØ±Ø¬Ù‰ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ù‹Ø§.",
    blockedContentError: "ØªÙ… Ø­Ø¸Ø± Ø§Ù„Ø±Ø¯ Ù„Ø£Ù†Ù‡ Ù‚Ø¯ ÙŠÙ†ØªÙ‡Ùƒ Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø©. ÙŠØ±Ø¬Ù‰ ØªØ¹Ø¯ÙŠÙ„ Ø³Ø¤Ø§Ù„Ùƒ.",
    imageLoadError: "ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©. ÙŠØ±Ø¬Ù‰ ØªØ¬Ø±Ø¨Ø© Ù…Ù„Ù Ø¢Ø®Ø±.",
    micPermissionError: "ØªÙ… Ø±ÙØ¶ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ù‡ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªØµÙØ­Ùƒ.",
    speechError: "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
    sources: "Ø§Ù„Ù…ØµØ¯Ø± (Ø§Ù„Ù…ØµØ§Ø¯Ø±):",
    theme: "Ø§Ù„Ø³Ù…Ø©",
    lightTheme: "ÙØ§ØªØ­",
    darkTheme: "Ø¯Ø§ÙƒÙ†",
    textSize: "Ø­Ø¬Ù… Ø§Ù„Ù†Øµ",
    smallSize: "Øµ",
    normalSize: "Ù…",
    largeSize: "Ùƒ",
    playbackSpeed: "Ø³Ø±Ø¹Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©",
    favorites: "Ù…ÙØ¶Ù„Ø§ØªÙŠ",
    noFavorites: "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙØ¶Ù„Ø§Øª Ø¨Ø¹Ø¯. Ø§Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø£ÙŠÙ‚ÙˆÙ†Ø© ğŸ”– Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© Ù„Ø­ÙØ¸Ù‡Ø§.",
    removeFavorite: "Ø¥Ø²Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…ÙØ¶Ù„Ø©",
    shareConversation: "Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
    copyTranscription: "Ù†Ø³Ø® Ø§Ù„Ù†Øµ",
    exportPdf: "ØªÙ†Ø²ÙŠÙ„ Ø¨ØµÙŠØºØ© PDF",
    transcriptionCopied: "ØªÙ… Ù†Ø³Ø® Ø§Ù„Ù†Øµ!",
    userProfile: "Ù…Ù„ÙÙŠ Ø§Ù„Ø´Ø®ØµÙŠ",
    userRole: "Ø£Ù†Ø§...",
    userLevel: "Ø§Ù„Ù…Ø³ØªÙˆÙ‰/Ø§Ù„ØµÙ",
    roleTeacher: "Ù…Ø¹Ù„Ù…",
    roleStudent: "Ø·Ø§Ù„Ø¨",
    roleParent: "ÙˆÙ„ÙŠ Ø£Ù…Ø±",
    summarize: "ØªÙ„Ø®ÙŠØµ",
    createQuiz: "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø®ØªØ¨Ø§Ø±",
    summarizing: "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ...",
    quizCreating: "Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...",
    quizCorrect: "ØµØ­ÙŠØ­!",
    quizIncorrect: "ØºÙŠØ± ØµØ­ÙŠØ­.",
    addFavoriteTooltip: "Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙØ¶Ù„Ø©",
    removeFavoriteTooltip: "Ø¥Ø²Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…ÙØ¶Ù„Ø©",
    summarizeTooltip: "ØªÙ„Ø®ÙŠØµ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰",
    createQuizTooltip: "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰",
    previewSoundTooltip: "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø³Ù…Ø© Ø§Ù„ØµÙˆØªÙŠØ©",
    clearHistoryTooltip: "Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø¨Ø´ÙƒÙ„ Ø¯Ø§Ø¦Ù…",
    copyTranscriptionTooltip: "Ù†Ø³Ø® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙƒÙ†Øµ",
    exportPdfTooltip: "ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨ØµÙŠØºØ© PDF",
    closeShareModalTooltip: "Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù†Ø§ÙØ°Ø©",
    userSender: "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
    assistantSender: "Khadija",
    playAudioTooltip: "ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©",
    pauseAudioTooltip: "Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„",
    appearanceSettings: "Ø§Ù„Ù…Ø¸Ù‡Ø±",
    soundSettings: "Ø§Ù„ØµÙˆØªÙŠØ§Øª",
    dataManagement: "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
    uploadImageTooltip: "Ø¥Ø±ÙØ§Ù‚ ØµÙˆØ±Ø©",
    assistantVoice: "ØµÙˆØª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©",
    voice: "Ø§Ù„ØµÙˆØª",
    pitch: "Ø­Ø¯Ø© Ø§Ù„ØµÙˆØª",
    previewVoice: "Ø§Ø³ØªÙ…Ø¹ Ø¥Ù„Ù‰ Ù…Ø¹Ø§ÙŠÙ†Ø©",
    previewVoiceText: "Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙƒØŒ Ø£Ù†Ø§ Khadija. ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ø£Ù† Ø£Ø³Ø§Ø¹Ø¯Ùƒ.",
    noVoiceAvailable: "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ØµÙˆØ§Øª Ù…ØªØ§Ø­Ø©",
    embed: "ØªØ¶Ù…ÙŠÙ†",
    embedTooltip: "Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙƒÙˆØ¯ Ø§Ù„ØªØ¶Ù…ÙŠÙ†",
    copyCode: "Ù†Ø³Ø® Ø§Ù„ÙƒÙˆØ¯",
    codeCopied: "ØªÙ… Ù†Ø³Ø® Ø§Ù„ÙƒÙˆØ¯!",
  },
};
// -------------------------------------


// Data Constants
const schoolLevels = [
    { value: "all", key: "Tous" },
    { value: "prescolaire", key: "PrÃ©scolaire" },
    { value: "elementaire-ci", key: "Ã‰lÃ©mentaire - CI" },
    { value: "elementaire-cp", key: "Ã‰lÃ©mentaire - CP" },
    { value: "elementaire-ce1", key: "Ã‰lÃ©mentaire - CE1" },
    { value: "elementaire-ce2", key: "Ã‰lÃ©mentaire - CE2" },
    { value: "elementaire-cm1", key: "Ã‰lÃ©mentaire - CM1" },
    { value: "elementaire-cm2", key: "Ã‰lÃ©mentaire - CM2" },
    { value: "moyen-6e", key: "Moyen - 6Ã¨me" },
    { value: "moyen-5e", key: "Moyen - 5Ã¨me" },
    { value: "moyen-4e", key: "Moyen - 4Ã¨me" },
    { value: "moyen-3e", key: "Moyen - 3Ã¨me" },
    { value: "secondaire-2nde", key: "Secondaire - Seconde" },
    { value: "secondaire-1ere", key: "Secondaire - PremiÃ¨re" },
    { value: "secondaire-tle", key: "Secondaire - Terminale" }
];

// Sound Profiles Definition
const soundProfiles = {
  default: {
    send: { type: 'triangle', freq1: 300, freq2: 150, gain: 0.2, dur: 0.1 },
    receive: { type: 'sine', freq1: 600, gain: 0.15, dur: 0.15 },
    startRec: { type: 'sine', freq1: 220, gain: 0.3, dur: 0.1 },
    stopRec: { type: 'sine', freq1: 440, gain: 0.3, dur: 0.1 },
  },
  soft: {
    send: { type: 'sine', freq1: 440, freq2: 330, gain: 0.1, dur: 0.15 },
    receive: { type: 'sine', freq1: 880, freq2: 660, gain: 0.08, dur: 0.2 },
    startRec: { type: 'sine', freq1: 300, gain: 0.15, dur: 0.1 },
    stopRec: { type: 'sine', freq1: 500, gain: 0.15, dur: 0.1 },
  },
  digital: {
    send: { type: 'square', freq1: 1000, freq2: 500, gain: 0.05, dur: 0.1 },
    receive: { type: 'square', freq1: 1500, gain: 0.05, dur: 0.1 },
    startRec: { type: 'sawtooth', freq1: 250, gain: 0.1, dur: 0.05 },
    stopRec: { type: 'sawtooth', freq1: 500, gain: 0.1, dur: 0.05 },
  },
};


// Speech Recognition
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
let recognition = null;
let isRecording = false;

// API Instances - declared here, initialized in main()
let ai = null;
let chat = null;


// --- Character Data ---
const character = {
    svg: `<svg viewBox="0 0 100 125" xmlns="http://www.w3.org/2000/svg">
    <defs>
      <radialGradient id="khadija-skin-new" cx="50%" cy="45%" r="60%" fx="55%" fy="40%">
        <stop offset="0%" stop-color="#A67B5B"></stop>
        <stop offset="100%" stop-color="#8C6442"></stop>
      </radialGradient>
      <linearGradient id="khadija-hair-new" x1="0%" y1="0%" x2="100%" y2="100%">
        <stop offset="0%" stop-color="#4A342E"></stop>
        <stop offset="100%" stop-color="#2D1E1A"></stop>
      </linearGradient>
      <radialGradient id="khadija-hair-highlight-new" cx="50%" cy="50%" r="50%">
        <stop offset="0%" stop-color="#C2A58C" stop-opacity="0.3"></stop>
        <stop offset="100%" stop-color="#C2A58C" stop-opacity="0"></stop>
      </radialGradient>
      <radialGradient id="khadija-eyes-new" cx="50%" cy="50%" r="50%">
        <stop offset="0%" stop-color="#694028"></stop>
        <stop offset="100%" stop-color="#402616"></stop>
      </radialGradient>
      <linearGradient id="khadija-hoodie" x1="0%" y1="0%" x2="0%" y2="100%">
        <stop offset="0%" stop-color="#FF9800"></stop>
        <stop offset="100%" stop-color="#FB8C00"></stop>
      </linearGradient>
       <linearGradient id="khadija-book" x1="0%" y1="0%" x2="100%" y2="0%">
        <stop offset="0%" stop-color="#5D4037"></stop>
        <stop offset="100%" stop-color="#4E342E"></stop>
      </linearGradient>
       <linearGradient id="khadija-glasses" x1="0%" y1="0%" x2="0%" y2="100%">
        <stop offset="0%" stop-color="#555555"></stop>
        <stop offset="100%" stop-color="#333333"></stop>
      </linearGradient>
      <filter id="drop-shadow-khadija" x="-20%" y="-20%" width="140%" height="140%">
        <feGaussianBlur in="SourceAlpha" stdDeviation="2.5"></feGaussianBlur>
        <feOffset dx="1" dy="4" result="offsetblur"></feOffset>
        <feFlood flood-color="rgba(0,0,0,0.2)"></feFlood>
        <feComposite in2="offsetblur" operator="in"></feComposite>
        <feMerge>
          <feMergeNode></feMergeNode>
          <feMergeNode in="SourceGraphic"></feMergeNode>
        </feMerge>
      </filter>
    </defs>
    <g class="avatar-body" style="filter: url(#drop-shadow-khadija);">
      <!-- Body -->
      <path d="M 50,60 C 30,62 25,80 28,125 L 72,125 C 75,80 70,62 50,60 Z" fill="url(#khadija-hoodie)"></path>
      <!-- Hoodie collar -->
      <path d="M 40,60 C 42,68 48,72 50,72 C 52,72 58,68 60,60 L 55,63 L 50,65 L 45,63 Z" fill="#F57C00"></path>
      <!-- Hoodie strings -->
      <path d="M45,70 C43,80 44,90 45,95" fill="none" stroke="#FB8C00" stroke-width="1.5" stroke-linecap="round"></path>
      <path d="M55,70 C57,80 56,90 55,95" fill="none" stroke="#FB8C00" stroke-width="1.5" stroke-linecap="round"></path>

      <!-- Book and Hands -->
      <g>
        <!-- Book -->
        <path d="M28,85 L72,85 L75,120 L25,120 Z" fill="url(#khadija-book)"></path>
        <path d="M50,86 L50,119" stroke="#3E2723" stroke-width="1"></path>
        <path d="M30,88 L48,88 L48,117 L30,117 Z" fill="#FBFBFB"></path>
        <path d="M52,88 L70,88 L70,117 L52,117 Z" fill="#FBFBFB"></path>
        
        <!-- Hands -->
        <path d="M20,95 C25,90 35,92 32,105 C35,100 28,95 20,95Z" fill="url(#khadija-skin-new)"></path>
        <path d="M80,95 C75,90 65,92 68,105 C65,100 72,95 80,95Z" fill="url(#khadija-skin-new)"></path>
      </g>
      
      <!-- Head -->
      <g class="avatar-head">
        <!-- Neck -->
        <rect x="46" y="52" width="8" height="10" fill="url(#khadija-skin-new)"></rect>
        <!-- Face -->
        <path d="M33,45 C33,25 67,25 67,45 C67,65 55,70 50,70 C45,70 33,65 33,45 Z" fill="url(#khadija-skin-new)"></path>
        
        <!-- Hair -->
        <g>
          <path d="M25,50 C 5,20 50,-10 95,20 C80,55 20,55 25,50 Z" fill="url(#khadija-hair-new)"></path>
          <circle cx="30" cy="20" r="18" fill="url(#khadija-hair-new)"></circle>
          <circle cx="70" cy="20" r="18" fill="url(#khadija-hair-new)"></circle>
          <circle cx="50" cy="15" r="20" fill="url(#khadija-hair-new)"></circle>
          <!-- Hair Highlights -->
          <circle cx="30" cy="20" r="15" fill="url(#khadija-hair-highlight-new)"></circle>
          <circle cx="70" cy="20" r="15" fill="url(#khadija-hair-highlight-new)"></circle>
          <!-- Hairband -->
          <path d="M38,28 Q50,23 62,28" stroke="#FF9800" stroke-width="4" fill="none" stroke-linecap="round"></path>
        </g>
        
        <!-- Eyes -->
        <g>
          <!-- Sclera -->
          <ellipse cx="41.5" cy="47" rx="5" ry="5.5" fill="white"></ellipse>
          <ellipse cx="58.5" cy="47" rx="5" ry="5.5" fill="white"></ellipse>
          <!-- Iris -->
          <circle cx="41.5" cy="48" r="3.5" fill="url(#khadija-eyes-new)"></circle>
          <circle cx="58.5" cy="48" r="3.5" fill="url(#khadija-eyes-new)"></circle>
          <!-- Highlight -->
          <circle cx="42.5" cy="46.5" r="1" fill="rgba(255,255,255,0.9)"></circle>
          <circle cx="59.5" cy="46.5" r="1" fill="rgba(255,255,255,0.9)"></circle>
        </g>
        
        <!-- Glasses -->
        <g fill="none" stroke="url(#khadija-glasses)" stroke-width="2.5" stroke-linecap="round">
          <circle cx="41.5" cy="47" r="7"></circle>
          <circle cx="58.5" cy="47" r="7"></circle>
          <path d="M48.5,47 Q50,45 51.5,47"></path>
        </g>
        
        <!-- Eyebrows -->
        <g fill="none" stroke="#2D1E1A" stroke-width="1.5" stroke-linecap="round">
          <path d="M36,38 C39,36 45,36 46,38"></path>
          <path d="M54,38 C55,36 61,36 64,38"></path>
        </g>
        
        <!-- Mouth -->
        <path d="M44,59 Q50,64 56,59" stroke="#6D4C41" stroke-width="1.5" fill="none" stroke-linecap="round"></path>
        
        <!-- Earrings -->
        <circle cx="32" cy="52" r="1.5" fill="#FFD700"></circle>
        <circle cx="68" cy="52" r="1.5" fill="#FFD700"></circle>
      </g>
    </g>
  </svg>`,
    getInstruction: (profileContext, name) => `Tu es "${name}", l'assistant IA bienveillant, pÃ©dagogue et passionnÃ© de la plateforme Senprof. Ta personnalitÃ© est chaleureuse, encourageante et trÃ¨s patiente. Tu es lÃ  pour guider tous les utilisateurs, qu'ils soient enseignants, Ã©lÃ¨ves ou parents.
${profileContext}
**Ta Mission Principale :** Aider les utilisateurs Ã  trouver, comprendre, et structurer les ressources pÃ©dagogiques de la plateforme Senprof. Tu peux Ã©galement **analyser les images** que les utilisateurs t'envoient pour identifier du contenu pÃ©dagogique, expliquer des concepts visuels, ou rÃ©pondre Ã  des questions sur ce qu'elles reprÃ©sentent.
**IMPORTANT : La Langue de l'Utilisateur est Prioritaire** Tu dois impÃ©rativement dÃ©tecter la langue de l'utilisateur (franÃ§ais, wolof, arabe) et lui rÃ©pondre systÃ©matiquement dans cette mÃªme langue.
**Ton et Style :**
*   **Chaleureux et Conversationnel :** Adopte un ton naturel et amical. Commence tes rÃ©ponses par des petites phrases pour accueillir l'utilisateur (par exemple : "Absolument !", "Je vois ce que vous voulez dire.", "C'est une excellente question !").
*   **Empathique et Rassurant :** Si un utilisateur exprime une difficultÃ©, reconnais-la (ex: "Je comprends que cela puisse Ãªtre compliquÃ©..."). Sois toujours positive et termine tes interactions sur une note encourageante ("N'hÃ©sitez pas si vous avez d'autres questions !").
**Tes Principes de Guidage :**
1.  **Source Exclusive :** Ta source d'information principale et **exclusive** est \`https://senprof.education.sn/\`. Toutes les ressources que tu proposes (liens web, documents PDF, etc.) **doivent impÃ©rativement** provenir de ce site. N'utilise **jamais** de liens externes. **RÃ¨gle non nÃ©gociable : Toute URL fournie qui ne commence pas par \`https://senprof.education.sn/\` est une erreur. Tu dois vÃ©rifier chaque lien avant de l'inclure.**
2.  **PrioritÃ© aux Liens Directs :** Ta tÃ¢che la plus importante est de fournir des liens directs vers les ressources finales. Quand un utilisateur demande un "exercice", une "leÃ§on", ou une "activitÃ©", ne te contente pas de donner un lien vers une page de catÃ©gorie. Cherche le lien le plus profond et spÃ©cifique possible. **Par exemple, un lien idÃ©al ressemble Ã  \`https://senprof.education.sn/courses/math/lecon1.pdf\`, plutÃ´t qu'un lien gÃ©nÃ©ral comme \`.../courses/math/\`.**
3.  **Analyse d'Image Pertinente :** Lorsque tu reÃ§ois une image, intÃ¨gre son analyse dans ta rÃ©ponse. Si un utilisateur te demande "Qu'est-ce que c'est ?", dÃ©cris l'image. S'il demande "Trouve-moi des exercices sur ce sujet" en envoyant une photo d'une cellule vÃ©gÃ©tale, identifie la cellule et recherche des ressources sur la biologie cellulaire sur la plateforme Senprof.
4.  **Expertise et PÃ©dagogie :** Structure tes rÃ©ponses de maniÃ¨re pÃ©dagogique.
5.  **AccÃ¨s direct :** Pour chaque ressource du site, fournis toujours le lien direct. **CRUCIAL :** Tu dois impÃ©rativement formater chaque URL comme un lien Markdown cliquable, par exemple : \`[Titre de l'exercice de maths](https://senprof.education.sn/courses/A1.xhtml)\`. Ne jamais afficher une URL sous forme de texte brut.
6.  **Transparence totale :** Si une ressource n'existe pas, dis-le gentiment et propose des alternatives pertinentes sur le site. Si tu ne peux pas comprendre une image, admets-le poliment.
7.  **AdaptabilitÃ© :** Utilise un langage clair et adaptÃ© Ã  ton interlocuteur (simple pour un Ã©lÃ¨ve, plus technique pour un enseignant).`
};


/**
 * Generates the system instruction based on current user settings.
 */
function getSystemInstruction() {
  const { userRole, userLevel } = settings;
  const profileContext = `L'utilisateur est un(e) '${userRole}' s'intÃ©ressant au niveau '${userLevel}'. Adapte tes rÃ©ponses Ã  ce profil.`;
  const characterName = "Khadija";
  
  return character.getInstruction(profileContext, characterName);
}

/**
 * Initializes or re-initializes the chat session with the current system instruction.
 */
function initializeChat() {
  if (!ai) return;
  chat = ai.chats.create({
    model: 'gemini-2.5-flash',
    config: {
      systemInstruction: getSystemInstruction(),
      tools: [{ googleSearch: {} }],
    },
  });
}

/**
 * Populates the level select dropdowns from the constant.
 */
function populateLevelSelects() {
    const optionsHtml = schoolLevels.map(level => `<option value="${level.value}">${level.key}</option>`).join('');
    userLevelSelect.innerHTML = optionsHtml;
}


/**
 * Updates all UI text elements to the selected language.
 * @param {string} lang The language code (e.g., 'fr', 'en').
 */
function updateUIText(lang) {
  const t = translations[lang] || translations.fr;

  // Set document direction for RTL support
  if (lang === 'ar') {
    document.documentElement.setAttribute('dir', 'rtl');
  } else {
    document.documentElement.setAttribute('dir', 'ltr');
  }
  document.documentElement.setAttribute('lang', lang);
  
  // Update static text using data attributes
  document.querySelectorAll('[data-translate-key]').forEach(el => {
    const key = el.getAttribute('data-translate-key');
    if (key && t[key]) {
      el.innerHTML = t[key];
    }
  });

  // Update tooltips using data attributes
  document.querySelectorAll('[data-translate-key-tooltip]').forEach(el => {
    const key = el.getAttribute('data-translate-key-tooltip');
    if (key && t[key]) {
      el.setAttribute('aria-label', t[key]);
      el.setAttribute('title', t[key]);
    }
  });


  // Update dynamic elements (placeholders, ARIA labels, titles)
  shareButton.setAttribute('aria-label', t.shareConversation);
  shareButton.setAttribute('title', t.shareConversation);
  settingsButton.setAttribute('aria-label', t.openSettings);
  settingsButton.setAttribute('title', t.openSettings);
  closeSettingsButton.setAttribute('aria-label', t.closeSettings);
  closeSettingsButton.setAttribute('title', t.closeSettings);
  helpButton.setAttribute('aria-label', t.help);
  helpButton.setAttribute('title', t.help);
  const micTooltip = isRecording ? t.stopRecording : t.recordMessage;
  micButton.setAttribute('aria-label', micTooltip);
  micButton.setAttribute('title', micTooltip);
  imageUploadButton.setAttribute('aria-label', t.uploadImageTooltip);
  imageUploadButton.setAttribute('title', t.uploadImageTooltip);
  submitButton.setAttribute('aria-label', t.sendMessage);
  submitButton.setAttribute('title', t.sendMessage);
  
  chatInput.placeholder = isRecording ? t.recordingPlaceholder : t.chatPlaceholder;
  
  // Update select value
  uiLangSelect.value = lang;
  renderFavorites(); // Re-render in case "no favorites" text needs translation
}

/**
 * Ensures the Web Audio API context is initialized.
 * @returns The shared AudioContext or null if not supported.
 */
function getAudioContext() {
  if (!audioContext) {
    try {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
    } catch (e) {
      console.error("Web Audio API is not supported in this browser.");
      return null;
    }
  }
  return audioContext;
}

/**
 * Plays a sound effect for a given action based on current settings.
 * @param {string} type The type of sound to play.
 * @param {string} [themeOverride] Optional theme to use for previews.
 */
function playSound(type, themeOverride) {
  if (!settings.soundEnabled && !themeOverride) return;
  
  const audioCtx = getAudioContext();
  if (!audioCtx) return;

  const theme = soundProfiles[themeOverride || settings.soundTheme];
  const sound = theme[type];
  if (!sound) return;

  const oscillator = audioCtx.createOscillator();
  const gainNode = audioCtx.createGain();

  oscillator.connect(gainNode);
  gainNode.connect(audioCtx.destination);

  gainNode.gain.setValueAtTime(0, audioCtx.currentTime);

  oscillator.type = sound.type;
  oscillator.frequency.setValueAtTime(sound.freq1, audioCtx.currentTime);
  if (sound.freq2) {
    oscillator.frequency.exponentialRampToValueAtTime(sound.freq2, audioCtx.currentTime + sound.dur);
  }
  gainNode.gain.linearRampToValueAtTime(sound.gain, audioCtx.currentTime + 0.01);
  gainNode.gain.linearRampToValueAtTime(0, audioCtx.currentTime + sound.dur);

  oscillator.start(audioCtx.currentTime);
  oscillator.stop(audioCtx.currentTime + sound.dur + 0.05);
}


/**
 * Stops any playing ambient background sounds with a fade-out.
 */
function stopAmbientSound() {
  // This function is now empty to disable ambient sounds.
}

/**
 * Starts playing a subtle, thematic ambient sound based on the current UI theme.
 */
function startAmbientSound() {
  // This function is now empty to disable ambient sounds.
}

/**
 * Adds interactive elements (bookmark, summarize, quiz) to an AI message.
 * @param {HTMLElement} messageElement The AI message element to process.
 */
function addInteractiveElements(messageElement) {
    const t = translations[settings.uiLang];
    const interactiveContainer = document.createElement('div');
    interactiveContainer.className = 'interactive-elements';
    
    // Bookmark logic
    const links = Array.from(messageElement.querySelectorAll('a[href*="senprof.education.sn/"]'));
    if (links.length > 0) {
        const url = links[0].href;
        const title = links[0].textContent || url;
        const isBookmarked = favorites.some(fav => fav.url === url);

        const bookmarkButton = document.createElement('button');
        bookmarkButton.className = 'bookmark-button';
        if(isBookmarked) bookmarkButton.classList.add('bookmarked');
        const bookmarkTooltip = isBookmarked ? t.removeFavoriteTooltip : t.addFavoriteTooltip;
        bookmarkButton.setAttribute('aria-label', bookmarkTooltip);
        bookmarkButton.setAttribute('title', bookmarkTooltip);
        bookmarkButton.innerHTML = 'ğŸ”–';
        
        bookmarkButton.addEventListener('click', () => {
            const favoriteIndex = favorites.findIndex(fav => fav.url === url);
            if (favoriteIndex > -1) {
                favorites.splice(favoriteIndex, 1);
                bookmarkButton.classList.remove('bookmarked');
            } else {
                favorites.push({ url, title });
                bookmarkButton.classList.add('bookmarked');
            }
            const newBookmarkTooltip = bookmarkButton.classList.contains('bookmarked') ? t.removeFavoriteTooltip : t.addFavoriteTooltip;
            bookmarkButton.setAttribute('aria-label', newBookmarkTooltip);
            bookmarkButton.setAttribute('title', newBookmarkTooltip);
            saveFavorites();
            renderFavorites();
        });
        interactiveContainer.appendChild(bookmarkButton);
    }
    
    // Text-to-Speech Button
    const audioButton = document.createElement('button');
    audioButton.className = 'audio-button';
    audioButton.setAttribute('aria-label', t.playAudioTooltip);
    audioButton.setAttribute('title', t.playAudioTooltip);
    audioButton.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zM9.5 16.5v-9l7 4.5-7 4.5z"></path></svg>`;
    
    audioButton.addEventListener('click', () => handleTextToSpeech(messageElement, audioButton));
    interactiveContainer.appendChild(audioButton);

    if (interactiveContainer.children.length > 0) {
        messageElement.appendChild(interactiveContainer);
    }
    
    // Summarize and Quiz buttons for each link
    links.forEach(link => {
        const url = link.href;
        const actionsContainer = document.createElement('div');
        actionsContainer.className = 'resource-actions';

        const summarizeButton = document.createElement('button');
        summarizeButton.innerHTML = `ğŸ” <span data-translate-key="summarize">${t.summarize}</span>`;
        summarizeButton.setAttribute('aria-label', t.summarizeTooltip);
        summarizeButton.title = t.summarizeTooltip;
        summarizeButton.onclick = () => handleSummarizeClick(url, actionsContainer);

        const quizButton = document.createElement('button');
        quizButton.innerHTML = `ğŸ§  <span data-translate-key="createQuiz">${t.createQuiz}</span>`;
        quizButton.setAttribute('aria-label', t.createQuizTooltip);
        quizButton.title = t.createQuizTooltip;
        quizButton.onclick = () => handleQuizClick(url, actionsContainer);
        
        actionsContainer.append(summarizeButton, quizButton);
        link.parentElement?.insertAdjacentElement('afterend', actionsContainer);
    });
}

/**
 * Resets the global audio state and UI.
 */
function resetAudioState() {
    stopAmbientSound();
    if (typeof speechSynthesis !== 'undefined') {
        speechSynthesis.cancel();
    }
    if (currentAudioSource) {
      currentAudioSource.onended = null; // Prevent the onended callback from firing on manual stop
      currentAudioSource.stop();
    }
    if (currentlyPlayingButton) {
        const t = translations[settings.uiLang];
        currentlyPlayingButton.classList.remove('speaking');
        currentlyPlayingButton.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zM9.5 16.5v-9l7 4.5-7 4.5z"></path></svg>`;
        currentlyPlayingButton.setAttribute('aria-label', t.playAudioTooltip);
        const associatedMessage = currentlyPlayingButton.closest('.message');
        if (associatedMessage) {
            associatedMessage.classList.remove('speaking-aloud');
        }
    }
    currentAudioSource = null;
    currentlyPlayingButton = null;
}

/**
 * Converts a base64 string to an ArrayBuffer.
 * @param {string} base64 The base64 encoded string.
 * @returns {ArrayBuffer} An ArrayBuffer.
 */
function base64ToArrayBuffer(base64) {
  const binaryString = window.atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes.buffer;
}

/**
 * Handles Text-to-Speech functionality for a message using the best available service.
 * @param {HTMLElement} messageElement The element containing the text to speak.
 * @param {HTMLButtonElement} button The audio button that was clicked.
 */
async function handleTextToSpeech(messageElement, button) {
  const t = translations[settings.uiLang];
  const wasPlayingThis = currentlyPlayingButton === button;

  resetAudioState();

  if (wasPlayingThis) {
    return;
  }
  
  const cleanText = messageElement.cloneNode(true);
  cleanText.querySelectorAll('.interactive-elements, .resource-actions, .action-result-container, .sources').forEach(el => el.remove());
  const textToSpeak = cleanText.textContent?.trim() || '';
  if (!textToSpeak) return;

  currentlyPlayingButton = button;
  button.classList.add('speaking');
  button.innerHTML = `<div class="loading-spinner"></div>`;
  button.setAttribute('aria-label', t.pauseAudioTooltip);
  messageElement.classList.add('speaking-aloud');

  const API_KEY = process.env.API_KEY;
  if (isGoogleTtsAvailable && API_KEY) {
    try {
      const response = await fetch(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${API_KEY}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          input: { text: textToSpeak },
          voice: { languageCode: 'fr-FR', name: 'fr-FR-Wavenet-E' },
          audioConfig: { audioEncoding: 'MP3', speakingRate: settings.playbackSpeed }
        })
      });
      
      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error.message || 'TTS API request failed');
      }
      const data = await response.json();
      const audioCtx = getAudioContext();
      if (!audioCtx) throw new Error("AudioContext not available");

      const audioBuffer = await audioCtx.decodeAudioData(base64ToArrayBuffer(data.audioContent));
      
      const source = audioCtx.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioCtx.destination);
      source.start(0);

      currentAudioSource = source;
      startAmbientSound();
      
      button.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zM8 16h8V8H8v8z"></path></svg>`;
      source.onended = resetAudioState;

    } catch (error) {
      console.error("Google TTS Error:", error);
      resetAudioState(); 
    }
  } else {
    // Fallback to native browser TTS
    if (typeof speechSynthesis === 'undefined') {
        console.error("Speech Synthesis API is not supported in this browser.");
        resetAudioState();
        return;
    }
    const utterance = new SpeechSynthesisUtterance(textToSpeak);
    const voices = speechSynthesis.getVoices();
    const selectedVoice = voices.find(voice => voice.name === settings.voiceName);
    
    utterance.voice = selectedVoice || voices.find(v => v.lang.startsWith(settings.uiLang)) || voices.find(v => v.lang.startsWith('fr')) || null;
    utterance.pitch = settings.pitch;
    utterance.rate = settings.playbackSpeed;
    
    button.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zM8 16h8V8H8v8z"></path></svg>`;
    utterance.onend = resetAudioState;
    utterance.onerror = (e) => {
        console.error("Native TTS Error:", e.error);
        resetAudioState();
    };
    speechSynthesis.speak(utterance);
  }
}


/**
 * Appends a message to the chat history.
 * @param {string} message The message content (HTML).
 * @param {'user' | 'ai'} sender The sender ('user' or 'ai').
 * @returns {HTMLElement} The created message element.
 */
function displayMessage(message, sender) {
  const messageElement = document.createElement('div');
  messageElement.classList.add('message', sender);
  messageElement.innerHTML = message;
  chatHistory.appendChild(messageElement);
  chatHistory.scrollTop = chatHistory.scrollHeight;

  if (sender === 'ai' && !messageElement.classList.contains('error')) {
      addInteractiveElements(messageElement);
  }
  return messageElement;
}

/**
 * Toggles the loading state of the UI.
 * @param {boolean} isLoading True to show loading, false to hide.
 */
function setLoading(isLoading) {
  if (isLoading) {
    loadingIndicator.classList.remove('hidden');
    chatInput.disabled = true;
    submitButton.disabled = true;
    micButton.disabled = true;
    imageUploadButton.disabled = true;
    langSelect.disabled = true;
    suggestionChipsContainer.classList.add('hidden');

    // Start dynamic text cycle
    const t = translations[settings.uiLang];
    const messages = [
        t.assistantThinking,
        t.analyzingRequest,
        t.consultingResources,
        t.formulatingResponse,
    ];
    let messageIndex = 0;
    
    // Set initial message
    loadingText.textContent = messages[messageIndex];

    if (loadingInterval) clearInterval(loadingInterval);
    
    loadingInterval = window.setInterval(() => {
        messageIndex = (messageIndex + 1) % messages.length;
        loadingText.classList.add('fade');
        setTimeout(() => {
            loadingText.textContent = messages[messageIndex];
            loadingText.classList.remove('fade');
        }, 500); // Corresponds to transition duration in CSS
    }, 3000); // Change text every 3 seconds

  } else {
    if (loadingInterval) {
      clearInterval(loadingInterval);
      loadingInterval = null;
    }
    
    loadingIndicator.classList.add('hidden');
    chatInput.disabled = false;
    submitButton.disabled = false;
    micButton.disabled = false;
    imageUploadButton.disabled = false;
    langSelect.disabled = false;
    chatInput.focus();
    if(chatInput.value.trim() === '') {
      renderSuggestions();
    }
  }
}

/**
 * Saves the current chat history to localStorage.
 */
function saveChatHistory() {
  try {
    if (chatHistoryLog.length > MAX_HISTORY_MESSAGES) {
      chatHistoryLog = chatHistoryLog.slice(chatHistoryLog.length - MAX_HISTORY_MESSAGES);
    }
    localStorage.setItem('senProfAssistantHistory', JSON.stringify(chatHistoryLog));
  } catch (error) {
    console.warn('Could not save chat history to localStorage:', error);
  }
}

/**
 * Loads chat history from localStorage and displays it.
 */
function loadChatHistory() {
  try {
    const savedHistory = localStorage.getItem('senProfAssistantHistory');
    if (savedHistory) {
      chatHistoryLog = JSON.parse(savedHistory);
      chatHistory.innerHTML = '';
      chatHistoryLog.forEach(msg => {
        // Re-rendering messages will also re-attach interactive elements
        const el = displayMessage(msg.content, msg.sender);
        // Re-apply error class if it exists in the stored HTML
        if (msg.content.includes('class="message ai error"')) {
            el.classList.add('error');
        }
      });
    }
  } catch (error) {
    console.warn('Could not load chat history from localStorage:', error);
    chatHistoryLog = [];
  }
}

// --- Error Handling ---
/**
 * Analyzes an error and returns a corresponding translation key.
 * @param {any} error The error object.
 * @returns {string} A string key for the translations object.
 */
function getErrorMessageKey(error) {
    const errorMessage = (error?.message || error.toString()).toLowerCase();
    
    if (errorMessage.includes('network') || errorMessage.includes('failed to fetch')) {
        return 'networkError';
    }
    if (errorMessage.includes('api key')) {
        return 'apiKeyError';
    }
    if (errorMessage.includes('[429]')) { // HTTP 429 Too Many Requests
        return 'rateLimitError';
    }
    if (errorMessage.includes('safety')) {
        return 'blockedContentError';
    }
    if (errorMessage.includes('[400]') || errorMessage.includes('[500]') || errorMessage.includes('[503]')) {
        return 'modelError';
    }
    
    return 'genericError';
}

/**
 * Displays a styled error message in the chat.
 * @param {any} error The original error object for console logging.
 * @param {string} [messageKey] An optional, specific message key to use.
 */
function displayError(error, messageKey) {
    const key = messageKey || getErrorMessageKey(error);
    const translatedMessage = translations[settings.uiLang][key] || translations[settings.uiLang].genericError;

    console.error('An error occurred:', error);

    const errorElement = displayMessage(translatedMessage, 'ai');
    errorElement.classList.add('error');
    
    // Create a snapshot of the element's state for the log
    const tempDiv = document.createElement('div');
    tempDiv.appendChild(errorElement.cloneNode(true));
    chatHistoryLog.push({ sender: 'ai', content: tempDiv.innerHTML });
    
    saveChatHistory();
}

/**
 * Handles the chat form submission.
 * @param {SubmitEvent} event The form submission event.
 */
async function handleFormSubmit(event) {
  event.preventDefault();
  if (!chat) {
    displayError(new Error("Chat not initialized"), 'apiKeyError');
    return;
  }
  const userMessage = chatInput.value.trim();

  if (!userMessage && !attachedImage) {
    return;
  }
  
  resetAudioState();

  // Create user message with image if attached
  let userMessageHTML = userMessage;
  if (attachedImage) {
    userMessageHTML += `<br><img src="${attachedImage.dataUrl}" class="user-image" alt="Image envoyÃ©e par l'utilisateur">`;
  }
  
  displayMessage(userMessageHTML, 'user');
  chatHistoryLog.push({ sender: 'user', content: userMessageHTML });
  
  playSound('send');
  chatInput.value = '';
  setLoading(true);

  // Construct a more specific prompt for the model to ensure site-specific search
  const modelQuery = `En te basant exclusivement sur des recherches sur "site:senprof.education.sn/", trouve les liens les plus directs et spÃ©cifiques possible (par exemple, vers un exercice .xhtml ou un document .pdf) pour la demande suivante : "${userMessage}"`;

  // Prepare content for API
  const messageParts = [];
  if (userMessage) {
    messageParts.push(modelQuery);
  }
  if (attachedImage) {
    messageParts.push({
      inlineData: {
        mimeType: attachedImage.mimeType,
        data: attachedImage.base64,
      }
    });
  }
  removeAttachedImage(); // Clear preview after preparing for sending

  try {
    const stream = await chat.sendMessageStream({ 
        message: messageParts 
    });

    const aiMessageElement = displayMessage('', 'ai');
    aiMessageElement.innerHTML = `<span class="typing-cursor"></span>`;
    playSound('receive');
    let fullResponse = '';
    const sources = new Set();

    for await (const chunk of stream) {
      fullResponse += chunk.text;
      const groundingChunks = chunk.candidates?.[0]?.groundingMetadata?.groundingChunks;
      if (groundingChunks) {
        for (const gc of groundingChunks) {
          // Strict filtering to ensure only nebula links are added
          if (gc.web?.uri && gc.web.uri.includes('senprof.education.sn/')) {
            sources.add(gc.web.uri);
          }
        }
      }
      aiMessageElement.innerHTML = (await marked.parse(fullResponse)).trim() + '<span class="typing-cursor"></span>';
      chatHistory.scrollTop = chatHistory.scrollHeight;
    }

    // --- START: ROBUST LINK HANDLING ---

    // Final render pass with full content
    aiMessageElement.innerHTML = await marked.parse(fullResponse);

    // Function to find plain text URLs in text nodes and convert them to <a> tags.
    const linkifyUrlsInElement = (element) => {
      const walker = document.createTreeWalker(element, NodeFilter.SHOW_TEXT, null);
      const nodesToProcess = [];
      let node;
      // First, collect all text nodes to avoid issues with modifying the DOM while iterating.
      while ((node = walker.nextNode())) {
        // Only process text nodes that are not already inside an <a> or <button> tag.
        if (node.parentElement?.closest('a, button') === null) {
          nodesToProcess.push(node);
        }
      }

      const urlRegex = /(https?:\/\/[^\s`()<>"]+)/g;
      nodesToProcess.forEach(textNode => {
        const text = textNode.textContent;
        if (text && urlRegex.test(text)) {
          const fragment = document.createDocumentFragment();
          let lastIndex = 0;

          // Use replace with a function to build the fragment
          text.replace(urlRegex, (match, offset) => {
            // Add text before the match
            if (offset > lastIndex) {
              fragment.appendChild(document.createTextNode(text.substring(lastIndex, offset)));
            }
            // Create and add the link
            const a = document.createElement('a');
            a.href = match;
            a.textContent = match;
            a.target = '_blank';
            a.rel = 'noopener noreferrer';
            fragment.appendChild(a);

            lastIndex = offset + match.length;
            return match; // Required by replace
          });

          // Add any remaining text after the last match
          if (lastIndex < text.length) {
            fragment.appendChild(document.createTextNode(text.substring(lastIndex)));
          }

          // Replace the original text node with the new fragment
          textNode.parentNode?.replaceChild(fragment, textNode);
        }
      });
    };

    // Apply the linkify function to the AI message content.
    linkifyUrlsInElement(aiMessageElement);
    
    // --- FOOLPROOF LINK FILTER (existing logic) ---
    const allLinks = aiMessageElement.querySelectorAll('a');
    allLinks.forEach(link => {
      const href = link.getAttribute('href');
      if (href && !href.startsWith('https://senprof.education.sn/') && !href.startsWith('http://senprof.education.sn/')) {
        const textContent = link.textContent || href;
        const textNode = document.createTextNode(textContent);
        link.parentNode?.replaceChild(textNode, link);
      }
    });

    // --- END: ROBUST LINK HANDLING ---


    if (sources.size > 0) {
      const sourcesElement = document.createElement('div');
      sourcesElement.classList.add('sources');
      let sourcesHTML = `<strong>${translations[settings.uiLang].sources || 'Source(s) :'}</strong><ul>`;
      sources.forEach(url => {
        sourcesHTML += `<li><a href="${url}" target="_blank" rel="noopener noreferrer">${url}</a></li>`;
      });
      sourcesHTML += '</ul>';
      
      sourcesElement.innerHTML = sourcesHTML;
      aiMessageElement.appendChild(sourcesElement);
      chatHistory.scrollTop = chatHistory.scrollHeight;
    }
    
    addInteractiveElements(aiMessageElement);
    chatHistoryLog.push({ sender: 'ai', content: aiMessageElement.innerHTML });
    saveChatHistory();

  } catch (error) {
    displayError(error);
  } finally {
    setLoading(false);
  }
}

// --- New Feature Handlers ---

async function handleSummarizeClick(url, container) {
    if (!chat) {
        const t = translations[settings.uiLang];
        container.innerHTML = `<div class="action-result-container error">${t.apiKeyError}</div>`;
        return;
    }
    resetAudioState();
    container.innerHTML = `<div class="action-result-container"><div class="loading-spinner"></div> ${translations[settings.uiLang].summarizing}</div>`;
    const prompt = `En tant qu'assistant pour un ${settings.userRole} de niveau ${settings.userLevel}, rÃ©sume le contenu de cette page en 3 points clÃ©s: ${url}. RÃ©ponds uniquement avec les points du rÃ©sumÃ©.`;
    try {
        const stream = await chat.sendMessageStream({ message: prompt });
        let fullResponse = '';
        container.innerHTML = `<div class="action-result-container"></div>`;
        const resultContainer = container.querySelector('.action-result-container');

        for await (const chunk of stream) {
            fullResponse += chunk.text;
            resultContainer.innerHTML = await marked.parse(fullResponse);
        }
    } catch (e) {
        console.error("Summarization failed", e);
        const t = translations[settings.uiLang];
        const key = getErrorMessageKey(e);
        container.innerHTML = `<div class="action-result-container error">${t[key]}</div>`;
    }
}

async function handleQuizClick(url, container) {
    if (!ai) {
        const t = translations[settings.uiLang];
        container.innerHTML = `<div class="action-result-container error">${t.apiKeyError}</div>`;
        return;
    }
    resetAudioState();
    container.innerHTML = `<div class="action-result-container"><div class="loading-spinner"></div> ${translations[settings.uiLang].quizCreating}</div>`;
    const prompt = `En te basant sur le contenu de la page ${url}, crÃ©e un quiz Ã  choix multiples de 3 questions. Pour chaque question, fournis 3 options de rÃ©ponse et indique l'index de la bonne rÃ©ponse (0, 1, ou 2).`;
    
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: prompt,
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        quiz: {
                            type: Type.ARRAY,
                            items: {
                                type: Type.OBJECT,
                                properties: {
                                    question: { type: Type.STRING },
                                    options: { type: Type.ARRAY, items: { type: Type.STRING } },
                                    correctAnswerIndex: { type: Type.INTEGER }
                                }
                            }
                        }
                    }
                }
            }
        });
        
        const quizData = JSON.parse(response.text).quiz;
        renderQuiz(quizData, container);

    } catch(e) {
        console.error("Quiz creation failed", e);
        const t = translations[settings.uiLang];
        const key = getErrorMessageKey(e);
        container.innerHTML = `<div class="action-result-container error">${t[key]}</div>`;
    }
}

function renderQuiz(quizData, container) {
    container.innerHTML = ''; // Clear loading
    const quizContainer = document.createElement('div');
    quizContainer.className = 'action-result-container';
    
    quizData.forEach((q, index) => {
        const questionEl = document.createElement('div');
        questionEl.className = 'quiz-container';
        questionEl.innerHTML = `<div class="quiz-question">${index + 1}. ${q.question}</div>`;
        
        const optionsEl = document.createElement('div');
        optionsEl.className = 'quiz-options';
        
        q.options.forEach((option, optIndex) => {
            const optionEl = document.createElement('div');
            optionEl.className = 'quiz-option';
            optionEl.textContent = option;
            optionEl.dataset.index = `${optIndex}`;
            
            optionEl.addEventListener('click', () => {
                if (optionsEl.classList.contains('answered')) return;
                optionsEl.classList.add('answered');
                const selectedIndex = parseInt(optionEl.dataset.index);
                
                if (selectedIndex === q.correctAnswerIndex) {
                    optionEl.classList.add('correct');
                } else {
                    optionEl.classList.add('incorrect');
                    optionsEl.querySelector(`[data-index='${q.correctAnswerIndex}']`)?.classList.add('correct');
                }
            }, { once: true });
            
            optionsEl.appendChild(optionEl);
        });
        
        questionEl.appendChild(optionsEl);
        quizContainer.appendChild(questionEl);
    });
    container.appendChild(quizContainer);
}


// --- Original Handlers ---

function handleMicClick() {
  if (!recognition) return;

  if (isRecording) {
    recognition.stop();
  } else {
    recognition.lang = langSelect.value;
    recognition.start();
  }
}

function handleHelpClick() {
  const t = translations[settings.uiLang];
  const helpMessage = `
    <strong>${t.helpTitle}</strong>
    <p>${t.helpP1}</p>
    <p>${t.helpP2}</p>
    <ul>
      <li>${t.helpLangs.split(', ').join('</li><li>')}</li>
    </ul>
    <p>${t.helpVoice}</p>
  `;
  displayMessage(helpMessage, 'ai');
  chatHistoryLog.push({ sender: 'ai', content: helpMessage });
  saveChatHistory();
}

function setupSpeechRecognition() {
  if (!SpeechRecognition) {
    micButton.classList.add('hidden');
    langSelect.classList.add('hidden');
    console.warn('Speech Recognition API not supported in this browser.');
    return;
  }

  recognition = new SpeechRecognition();
  recognition.interimResults = true;
  recognition.onstart = () => { isRecording = true; micButton.classList.add('recording'); updateUIText(settings.uiLang); playSound('startRec'); };
  recognition.onend = () => { isRecording = false; micButton.classList.remove('recording'); updateUIText(settings.uiLang); playSound('stopRec'); };
  recognition.onerror = (event) => {
    let errorMessageKey = 'speechError';
    if (event.error === 'not-allowed' || event.error === 'permission-denied') {
      errorMessageKey = 'micPermissionError';
    } else if (event.error === 'network') {
      errorMessageKey = 'networkError';
    }
    displayError(event.error, errorMessageKey);
  };
  recognition.onresult = (event) => {
    let interimTranscript = '', finalTranscript = '';
    for (let i = event.resultIndex; i < event.results.length; ++i) {
      if (event.results[i].isFinal) finalTranscript += event.results[i][0].transcript;
      else interimTranscript += event.results[i][0].transcript;
    }
    chatInput.value = finalTranscript || interimTranscript;
    if (finalTranscript) chatForm.requestSubmit();
  };
  micButton.addEventListener('click', handleMicClick);
}

function flashButton(button) {
  button.classList.add('shortcut-active');
  setTimeout(() => button.classList.remove('shortcut-active'), 400);
}

function setupKeyboardShortcuts() {
  document.addEventListener('keydown', (event) => {
    const isCmdOrCtrl = event.metaKey || event.ctrlKey;
    if (event.key === 'Enter' && isCmdOrCtrl && chatInput.value.trim() && !submitButton.disabled) {
      event.preventDefault(); chatForm.requestSubmit(); flashButton(submitButton);
    }
    if (event.key.toLowerCase() === 's' && isCmdOrCtrl && event.shiftKey && !micButton.disabled) {
      event.preventDefault(); handleMicClick(); flashButton(micButton);
    }
  });
}

function updateAvatar() {
    avatarContainer.innerHTML = character.svg;
}

/**
 * Populates the voice selection dropdown with available system voices.
 */
function populateVoiceList() {
    if (typeof speechSynthesis === 'undefined') {
        voiceSelect.innerHTML = '';
        const option = document.createElement('option');
        option.textContent = translations[settings.uiLang].noVoiceAvailable;
        voiceSelect.appendChild(option);
        return;
    }
    
    const voices = speechSynthesis.getVoices();
    voiceSelect.innerHTML = '';

    if (voices.length === 0) {
        const option = document.createElement('option');
        option.textContent = translations[settings.uiLang].noVoiceAvailable;
        voiceSelect.appendChild(option);
        return;
    }

    const lang = settings.uiLang;
    // Prioritize voices for the current language
    voices.filter(voice => voice.lang.startsWith(lang))
          .forEach(voice => {
        const option = document.createElement('option');
        option.textContent = `${voice.name} (${voice.lang})`;
        option.setAttribute('data-lang', voice.lang);
        option.setAttribute('data-name', voice.name);
        voiceSelect.appendChild(option);
    });

    // Add a separator if there were language-specific voices
    if (voiceSelect.options.length > 0 && voiceSelect.options.length < voices.length) {
        const separator = document.createElement('option');
        separator.disabled = true;
        separator.textContent = 'â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€';
        voiceSelect.appendChild(separator);
    }

    // Add the rest of the voices
    voices.filter(voice => !voice.lang.startsWith(lang))
          .forEach(voice => {
        const option = document.createElement('option');
        option.textContent = `${voice.name} (${voice.lang})`;
        option.setAttribute('data-lang', voice.lang);
        option.setAttribute('data-name', voice.name);
        voiceSelect.appendChild(option);
    });

    if (settings.voiceName) {
        voiceSelect.value = settings.voiceName;
    }
    if (voiceSelect.selectedIndex === -1) {
        voiceSelect.selectedIndex = 0;
    }
}


/**
 * Plays a preview of the selected voice settings.
 */
async function handleVoicePreview() {
    const t = translations[settings.uiLang];
    const previewText = t.previewVoiceText;
    const wasPlayingThis = currentlyPlayingButton === voicePreviewButton;

    resetAudioState();
    if (wasPlayingThis) return;

    currentlyPlayingButton = voicePreviewButton;
    const originalText = voicePreviewButton.innerHTML;
    voicePreviewButton.innerHTML = `<div class="loading-spinner" style="width: 1.2em; height: 1.2em; border-width: 2px; display: inline-block; vertical-align: middle;"></div>`;
    voicePreviewButton.disabled = true;

    const onEnd = () => {
        resetAudioState();
        voicePreviewButton.innerHTML = originalText;
        voicePreviewButton.disabled = false;
    };
    
    const API_KEY = process.env.API_KEY;
    if (isGoogleTtsAvailable && API_KEY) {
        try {
            const response = await fetch(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${API_KEY}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    input: { text: previewText },
                    voice: { languageCode: 'fr-FR', name: 'fr-FR-Wavenet-E' },
                    audioConfig: { audioEncoding: 'MP3', speakingRate: settings.playbackSpeed }
                })
            });
            if (!response.ok) throw new Error('Preview TTS failed');
            const data = await response.json();
            const audioCtx = getAudioContext();
            if (!audioCtx) return;
            const audioBuffer = await audioCtx.decodeAudioData(base64ToArrayBuffer(data.audioContent));
            const source = audioCtx.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioCtx.destination);
            source.start(0);
            currentAudioSource = source;
            startAmbientSound();
            source.onended = onEnd;
        } catch (e) {
            console.error("Voice preview failed", e);
            onEnd();
        }
    } else {
        if (typeof speechSynthesis === 'undefined') {
            console.error("Speech Synthesis API is not supported in this browser.");
            onEnd();
            return;
        }
        const utterance = new SpeechSynthesisUtterance(previewText);
        const voices = speechSynthesis.getVoices();
        const selectedVoice = voices.find(voice => voice.name === settings.voiceName);
        utterance.voice = selectedVoice || voices.find(v => v.lang.startsWith(settings.uiLang)) || null;
        utterance.pitch = settings.pitch;
        utterance.rate = settings.playbackSpeed;
        utterance.onend = onEnd;
        utterance.onerror = (e) => {
            console.error("Native TTS Preview Error:", e.error);
            onEnd();
        };
        speechSynthesis.speak(utterance);
    }
}

function setupSettings() {
  settingsButton.addEventListener('click', () => { chatContainer.classList.add('settings-visible'); renderFavorites(); });
  closeSettingsButton.addEventListener('click', () => chatContainer.classList.remove('settings-visible'));
  
  const handleProfileChange = () => {
    settings.userRole = userRoleSelect.value;
    settings.userLevel = userLevelSelect.value;
    saveSettings();
    initializeChat(); // Re-init chat with new system prompt
    if (chatHistoryLog.length <= 1) { // Only refresh if conversation hasn't started
        renderSuggestions();
    }
  };
  userRoleSelect.addEventListener('change', handleProfileChange);
  userLevelSelect.addEventListener('change', handleProfileChange);

  uiLangSelect.addEventListener('change', () => { 
    settings.uiLang = uiLangSelect.value; 
    updateUIText(settings.uiLang); 
    if (!isGoogleTtsAvailable) populateVoiceList();
    saveSettings(); 
  });
  
  themeToggle.addEventListener('click', (e) => {
    const target = e.target;
    if (target.matches('.theme-button')) {
      settings.theme = target.dataset.theme;
      body.setAttribute('data-theme', settings.theme);
      const previouslyActive = themeToggle.querySelector('.active');
      if (previouslyActive) {
        previouslyActive.classList.remove('active');
        previouslyActive.setAttribute('aria-pressed', 'false');
      }
      target.classList.add('active');
      target.setAttribute('aria-pressed', 'true');
      saveSettings();
    }
  });

  textSizeToggle.addEventListener('click', (e) => {
    const target = e.target;
    if (target.matches('.text-size-button')) {
      settings.textSize = target.dataset.size;
      chatContainer.setAttribute('data-text-size', settings.textSize);
      const previouslyActive = textSizeToggle.querySelector('.active');
      if (previouslyActive) {
        previouslyActive.classList.remove('active');
        previouslyActive.setAttribute('aria-pressed', 'false');
      }
      target.classList.add('active');
      target.setAttribute('aria-pressed', 'true');
      saveSettings();
    }
  });
  
  playbackSpeedToggle.addEventListener('click', (e) => {
    const target = e.target;
    if (target.matches('.playback-speed-button')) {
      settings.playbackSpeed = parseFloat(target.dataset.speed || '1');
      const previouslyActive = playbackSpeedToggle.querySelector('.active');
      if (previouslyActive) {
        previouslyActive.classList.remove('active');
        previouslyActive.setAttribute('aria-pressed', 'false');
      }
      target.classList.add('active');
      target.setAttribute('aria-pressed', 'true');
      saveSettings();
    }
  });

  soundToggle.addEventListener('change', () => { settings.soundEnabled = soundToggle.checked; saveSettings(); });
  soundThemeGroup.addEventListener('change', (event) => {
    const target = event.target;
    if (target.name === 'sound-theme') {
      settings.soundTheme = target.value;
      playSound('receive'); saveSettings();
    }
  });
  soundThemeGroup.querySelectorAll('.preview-button').forEach(button => {
    button.addEventListener('click', () => {
      const theme = button.getAttribute('data-theme');
      if(theme) playSound('receive', theme);
    });
  });

  voiceSelect.addEventListener('change', () => {
    const selectedOption = voiceSelect.options[voiceSelect.selectedIndex];
    settings.voiceName = selectedOption.getAttribute('data-name') || '';
    saveSettings();
  });
  pitchSlider.addEventListener('input', () => {
    settings.pitch = parseFloat(pitchSlider.value);
    saveSettings();
  });

  voicePreviewButton.addEventListener('click', handleVoicePreview);

  clearHistoryButton.addEventListener('click', () => {
    resetAudioState();
    localStorage.removeItem('senProfAssistantHistory');
    chatHistoryLog = [];
    chatHistory.innerHTML = '';
    const welcomeMessage = translations[settings.uiLang].welcomeMessage;
    displayMessage(welcomeMessage, 'ai');
    chatHistoryLog.push({ sender: 'ai', content: welcomeMessage });
    chatContainer.classList.remove('settings-visible');
  });
}

function saveSettings() {
  try {
    localStorage.setItem('senProfAssistantSettings', JSON.stringify(settings));
  } catch (error) {
    console.warn('Could not save settings to localStorage:', error);
  }
}

function loadSettings() {
  try {
    const savedSettings = localStorage.getItem('senProfAssistantSettings');
    if (savedSettings) {
      settings = { ...settings, ...JSON.parse(savedSettings) };
    }
  } catch (error) {
    console.warn('Could not load settings from localStorage:', error);
  }

  // Update UI
  updateAvatar();
  body.setAttribute('data-theme', settings.theme);
  const oldActiveTheme = themeToggle.querySelector('.active');
  if(oldActiveTheme) {
      oldActiveTheme.classList.remove('active');
      oldActiveTheme.setAttribute('aria-pressed', 'false');
  }
  const newActiveTheme = themeToggle.querySelector(`[data-theme="${settings.theme}"]`);
  if(newActiveTheme) {
      newActiveTheme.classList.add('active');
      newActiveTheme.setAttribute('aria-pressed', 'true');
  }
  
  chatContainer.setAttribute('data-text-size', settings.textSize);
  const oldActiveSize = textSizeToggle.querySelector('.active');
  if(oldActiveSize) {
      oldActiveSize.classList.remove('active');
      oldActiveSize.setAttribute('aria-pressed', 'false');
  }
  const newActiveSize = textSizeToggle.querySelector(`[data-size="${settings.textSize}"]`);
  if(newActiveSize) {
      newActiveSize.classList.add('active');
      newActiveSize.setAttribute('aria-pressed', 'true');
  }

  const oldActiveSpeed = playbackSpeedToggle.querySelector('.active');
  if(oldActiveSpeed) {
      oldActiveSpeed.classList.remove('active');
      oldActiveSpeed.setAttribute('aria-pressed', 'false');
  }
  const newActiveSpeed = playbackSpeedToggle.querySelector(`[data-speed="${settings.playbackSpeed}"]`);
  if(newActiveSpeed) {
      newActiveSpeed.classList.add('active');
      newActiveSpeed.setAttribute('aria-pressed', 'true');
  }

  soundToggle.checked = settings.soundEnabled;
  (document.querySelector(`input[name="sound-theme"][value="${settings.soundTheme}"]`))?.setAttribute('checked', 'true');
  uiLangSelect.value = settings.uiLang;
  userRoleSelect.value = settings.userRole;
  userLevelSelect.value = settings.userLevel;
  pitchSlider.value = String(settings.pitch);
}

function saveFavorites() {
  localStorage.setItem('senProfAssistantFavorites', JSON.stringify(favorites));
}

function loadFavorites() {
  try {
    const saved = localStorage.getItem('senProfAssistantFavorites');
    if (saved) favorites = JSON.parse(saved);
  } catch (e) {
    console.warn('Could not load favorites', e);
    favorites = [];
  }
}

function renderFavorites() {
  const t = translations[settings.uiLang];
  favoritesList.innerHTML = '';
  if (favorites.length === 0) {
    favoritesList.innerHTML = `<p class="no-favorites">${t.noFavorites}</p>`;
    return;
  }

  favorites.forEach((fav, index) => {
    const item = document.createElement('div');
    item.className = 'favorite-item';
    item.innerHTML = `
      <a href="${fav.url}" target="_blank" rel="noopener noreferrer">${fav.title}</a>
      <button class="remove-favorite-button" data-index="${index}" aria-label="${t.removeFavorite}" title="${t.removeFavorite}">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
      </button>
    `;
    favoritesList.appendChild(item);
  });

  favoritesList.querySelectorAll('.remove-favorite-button').forEach(button => {
    button.addEventListener('click', (e) => {
      const index = parseInt(e.currentTarget.dataset.index, 10);
      favorites.splice(index, 1);
      saveFavorites();
      renderFavorites();
      chatHistory.querySelectorAll('.message.ai').forEach(m => {
          const oldInteractive = m.querySelector('.interactive-elements');
          if(oldInteractive) oldInteractive.remove();
          addInteractiveElements(m)
      });
    });
  });
}

async function generateSuggestions() {
  if (!ai) return [];
  const { userRole, userLevel, uiLang } = settings;
  const t = translations[uiLang] || translations.fr;

  const roleKeyMap = {
    'enseignant': 'roleTeacher',
    'eleve': 'roleStudent',
    'parent': 'roleParent'
  };
  const userRoleKey = roleKeyMap[userRole];
  const translatedRole = t[userRoleKey] || userRole;
  const levelKey = schoolLevels.find(l => l.value === userLevel)?.key || userLevel;

  const prompt = `You are Khadija, an assistant for Senprof, an educational platform. A user with the profile '${translatedRole}' for school level '${levelKey}' is using the chat. The current interface language is '${uiLang}'. Generate 3 short, relevant, and engaging questions (max 50 chars) in the language '${uiLang}' that this user might ask. These questions will be displayed as clickable suggestion chips. For a teacher, suggest lesson plans or resources. For a student, suggest exercises or explanations. For a parent, suggest ways to help their child. Respond ONLY with a JSON object containing a "suggestions" array of strings.`;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            suggestions: {
              type: Type.ARRAY,
              items: { type: Type.STRING }
            }
          }
        }
      }
    });

    const result = JSON.parse(response.text);
    if (result.suggestions && Array.isArray(result.suggestions) && result.suggestions.length > 0) {
      return result.suggestions.slice(0, 3); // Ensure only 3 are returned
    }
    return [];
  } catch (error) {
    console.error("Failed to generate suggestions:", error);
    return [];
  }
}


async function renderSuggestions() {
  // Only show suggestions at the start of a conversation.
  if (chatHistoryLog.length > 1) {
      suggestionChipsContainer.classList.add('hidden');
      suggestionChipsContainer.innerHTML = '';
      return;
  }
  // Prevent re-fetching or showing if user is typing.
  if (isFetchingSuggestions || chatInput.value.trim() !== '') {
    return;
  }

  isFetchingSuggestions = true;
  suggestionChipsContainer.innerHTML = ''; // Clear previous
  suggestionChipsContainer.classList.remove('hidden');

  // Show placeholders while loading
  for (let i = 0; i < 3; i++) {
    const placeholder = document.createElement('div');
    placeholder.className = 'suggestion-chip-placeholder';
    suggestionChipsContainer.appendChild(placeholder);
  }

  let suggestions = [];
  try {
    suggestions = await generateSuggestions();
  } finally {
    isFetchingSuggestions = false;
  }
  
  if (suggestions.length === 0) {
    suggestions = fallbackSuggestions;
  }

  // If user started typing or a message was sent while we were fetching, abort rendering.
  if (chatInput.value.trim() !== '' || loadingIndicator.classList.contains('hidden') === false) {
    suggestionChipsContainer.classList.add('hidden');
    suggestionChipsContainer.innerHTML = '';
    return;
  }

  suggestionChipsContainer.innerHTML = ''; // Clear placeholders
  suggestions.slice(0, 3).forEach(text => { // Ensure max 3
    const chip = document.createElement('button');
    chip.className = 'suggestion-chip';
    chip.textContent = text;
    chip.addEventListener('click', () => { 
      chatInput.value = text; 
      chatForm.requestSubmit(); 
    });
    suggestionChipsContainer.appendChild(chip);
  });
}

function setupShareModal() {
  shareButton.addEventListener('click', () => {
      shareModalOverlay.classList.remove('hidden');
      embedCodeContainer.classList.add('hidden'); // Reset state
  });
  closeShareModalButton.addEventListener('click', () => shareModalOverlay.classList.add('hidden'));
  shareModalOverlay.addEventListener('click', (e) => {
    if (e.target === shareModalOverlay) shareModalOverlay.classList.add('hidden');
  });
  copyTranscriptionButton.addEventListener('click', copyTranscription);
  exportPdfButton.addEventListener('click', exportToPdf);

  // Embed functionality
  embedButton.addEventListener('click', () => {
    const currentUrl = new URL(window.location.href);
    currentUrl.searchParams.set('mode', 'iframe');
    
    // Clean up URL display
    const urlString = currentUrl.toString();
    const embedCode = `<div style="position: fixed; bottom: 20px; right: 20px; width: 400px; height: 600px; max-height: 80vh; max-width: 90vw; z-index: 9999; box-shadow: 0 10px 25px rgba(0,0,0,0.2); border-radius: 12px; overflow: hidden; background: #fff;"><iframe src="${urlString}" width="100%" height="100%" style="border:none;" allow="microphone" title="Assistant Khadija"></iframe></div>`;
    
    embedCodeTextarea.value = embedCode;
    embedCodeContainer.classList.remove('hidden');
  });

  copyEmbedCodeButton.addEventListener('click', async () => {
      await navigator.clipboard.writeText(embedCodeTextarea.value);
      const originalText = copyEmbedCodeButton.textContent;
      const t = translations[settings.uiLang];
      copyEmbedCodeButton.textContent = t.codeCopied;
      setTimeout(() => { copyEmbedCodeButton.textContent = originalText; }, 2000);
  });
}

// --- Image Upload ---

function setupImageUpload() {
  imageUploadButton.addEventListener('click', () => imageUploadInput.click());
  imageUploadInput.addEventListener('change', handleImageSelection);
  removeImageButton.addEventListener('click', removeAttachedImage);
}

function handleImageSelection(event) {
  const input = event.target;
  const file = input.files?.[0];

  if (file && file.type.startsWith('image/')) {
    const reader = new FileReader();
    reader.onload = (e) => {
      const dataUrl = e.target?.result;
      const base64 = dataUrl.split(',')[1];
      attachedImage = {
        base64,
        mimeType: file.type,
        dataUrl,
      };
      imagePreview.src = dataUrl;
      imagePreviewContainer.classList.remove('hidden');
    };
    reader.onerror = () => {
      displayError(reader.error, 'imageLoadError');
      removeAttachedImage();
    };
    reader.readAsDataURL(file);
  }
}

function removeAttachedImage() {
  attachedImage = null;
  imageUploadInput.value = ''; // Reset file input
  imagePreviewContainer.classList.add('hidden');
}

async function copyTranscription() {
  const t = translations[settings.uiLang];
  const header = `${t.appTitle}\n${t.appSubtitle}\n\n====================\n\n`;
  
  const userSender = t.userSender || 'User';
  const assistantSender = t.assistantSender || 'Assistant';
  
  const body = chatHistoryLog.map(msg => {
    const sender = msg.sender === 'user' ? userSender : assistantSender;
    return `${sender}:\n${msg.content.replace(/<[^>]+>/g, '')}`;
  }).join('\n\n');

  const text = header + body;
  try {
    await navigator.clipboard.writeText(text);
    const originalText = copyTranscriptionButton.textContent;
    copyTranscriptionButton.textContent = t.transcriptionCopied;
    setTimeout(() => { copyTranscriptionButton.textContent = originalText; }, 2000);
  } catch (err) {
    console.error('Failed to copy text: ', err);
  }
}

function exportToPdf() {
  const t = translations[settings.uiLang];
  const printWindow = window.open('', '_blank');
  if (printWindow) {
    printWindow.document.write(`
      <html>
        <head>
          <title>${t.appTitle} - Conversation</title>
          <link rel="stylesheet" href="index.css">
        </head>
        <body class="pdf-export" data-theme="${settings.theme}">
          <div class="chat-container">
            <header>
              <div class="header-text">
                <h1>${t.appTitle}</h1>
                <p>${t.appSubtitle}</p>
              </div>
            </header>
            <div id="chat-history">${chatHistory.innerHTML}</div>
          </div>
        </body>
      </html>
    `);
    printWindow.document.close();
    printWindow.focus();
    // A small delay is needed for styles to apply before printing
    setTimeout(() => {
      printWindow.print();
      printWindow.close();
    }, 500);
  }
}

/**
 * Checks if the Google Cloud TTS API is available and configures the UI accordingly.
 */
async function initializeTts() {
    const API_KEY = process.env.API_KEY;
    if (!API_KEY) {
        isGoogleTtsAvailable = false;
        body.dataset.ttsService = 'native';
        if (typeof speechSynthesis !== 'undefined' && speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = populateVoiceList;
        }
        populateVoiceList();
        return;
    }

    try {
        const response = await fetch(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${API_KEY}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                input: { text: 'test' },
                voice: { languageCode: 'fr-FR', name: 'fr-FR-Wavenet-E' },
                audioConfig: { audioEncoding: 'MP3' }
            })
        });
        isGoogleTtsAvailable = response.ok;
    } catch (error) {
        isGoogleTtsAvailable = false;
    }

    body.dataset.ttsService = isGoogleTtsAvailable ? 'google' : 'native';

    if (!isGoogleTtsAvailable) {
        // Populate voices for native TTS
        if (typeof speechSynthesis !== 'undefined' && speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = populateVoiceList;
        }
        populateVoiceList();
    }
}

async function main() {
  // --- Step 1: Load settings and set up the basic UI ---
  loadSettings();
  updateUIText(settings.uiLang);
  populateLevelSelects();
  loadFavorites();

  // --- Step 2: Set up all UI event listeners that DON'T require an immediate API call ---
  setupSpeechRecognition();
  setupKeyboardShortcuts();
  setupSettings();
  setupShareModal();
  setupImageUpload();
  helpButton.addEventListener('click', handleHelpClick);
  await initializeTts();
  
  // --- Step 3: Check for Embed Mode ---
  const urlParams = new URLSearchParams(window.location.search);
  if (urlParams.get('mode') === 'iframe' || urlParams.get('embed') === 'true') {
      chatContainer.classList.add('is-embedded');
      // In embed mode, we might want to disable the share/settings buttons in the header to save space, or keep them.
      // For now, let's keep them accessible but ensure layout works.
  }

  // --- Step 4: Check for API Key and initialize AI services or enter error state ---
  const API_KEY = process.env.API_KEY;
  if (!API_KEY) {
    displayError(new Error('API key not found'), 'apiKeyError');
    // Disable form functionality since API is not available
    chatInput.disabled = true;
    submitButton.disabled = true;
    micButton.disabled = true;
    imageUploadButton.disabled = true;
    suggestionChipsContainer.classList.add('hidden');
    chatInput.placeholder = translations[settings.uiLang].apiKeyError;
  } else {
    // API Key is present, initialize and set up full chat functionality
    ai = new GoogleGenAI({ apiKey: API_KEY });
    initializeChat();
    
    loadChatHistory();
    
    chatForm.addEventListener('submit', handleFormSubmit);
    chatInput.addEventListener('input', () => {
      if(chatInput.value.trim() !== '') {
        suggestionChipsContainer.classList.add('hidden');
      } else {
        renderSuggestions();
      }
    });

    if (chatHistoryLog.length === 0) {
      const welcomeMessage = translations[settings.uiLang].welcomeMessage;
      displayMessage(welcomeMessage, 'ai');
      chatHistoryLog.push({ sender: 'ai', content: welcomeMessage });
    }

    renderSuggestions();
  }
}

main();
